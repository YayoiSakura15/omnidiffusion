# OmniFlow è®­ç»ƒå’Œæ¨ç†ç¯å¢ƒ

å®Œæ•´çš„ OmniFlow å¤šæ¨¡æ€ç”Ÿæˆæ¨¡å‹è®­ç»ƒå’Œæ¨ç†ç¯å¢ƒé…ç½®æŒ‡å—ã€‚

---

## ğŸ“‹ ç›®å½•

- [ç›®å½•ç»“æ„](#-ç›®å½•ç»“æ„)
- [å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹-5åˆ†é’Ÿ)
- [ç¯å¢ƒé…ç½®](#-ç¯å¢ƒé…ç½®)
- [æ•°æ®é›†ä¸‹è½½](#-æ•°æ®é›†ä¸‹è½½)
- [æ¨¡å‹ä¸‹è½½](#-æ¨¡å‹ä¸‹è½½)
- [è®­ç»ƒæ¨¡å‹](#-è®­ç»ƒæ¨¡å‹)
- [å®éªŒé…ç½®](#-å®éªŒé…ç½®)
- [è¯„ä¼°æ¨¡å‹](#-è¯„ä¼°æ¨¡å‹)
- [å¸¸è§é—®é¢˜](#-å¸¸è§é—®é¢˜)

---

## ğŸ“ ç›®å½•ç»“æ„

```
qf/
â”œâ”€â”€ dataset/                      # æ•°æ®é›†ç›®å½•
â”‚   â”œâ”€â”€ download_data.py         # æ•°æ®ä¸‹è½½è„šæœ¬
â”‚   â””â”€â”€ data/                    # ä¸‹è½½åçš„æ•°æ®
â””â”€â”€ jiangqf/OmniFlows/           # OmniFlow ä¸»é¡¹ç›®ï¼ˆå½“å‰ç›®å½•ï¼‰
    â”œâ”€â”€ README.md                # æœ¬æ–‡ä»¶
    â”œâ”€â”€ setup.sh                 # ä¸€é”®ç¯å¢ƒé…ç½®
    â”œâ”€â”€ download_models.py       # æ¨¡å‹ä¸‹è½½
    â”œâ”€â”€ requirements.txt         # Python ä¾èµ–
    â”œâ”€â”€ run_example.sh           # å¿«é€Ÿè®­ç»ƒç¤ºä¾‹
    â”œâ”€â”€ models/                  # é¢„è®­ç»ƒæ¨¡å‹
    â”œâ”€â”€ checkpoints/             # è®­ç»ƒæ£€æŸ¥ç‚¹
    â”œâ”€â”€ logs/                    # è®­ç»ƒæ—¥å¿—
    â”œâ”€â”€ omniflow/                # æ ¸å¿ƒä»£ç 
    â”œâ”€â”€ scripts/                 # è®­ç»ƒå’Œè¯„ä¼°è„šæœ¬
    â”‚   â”œâ”€â”€ train_text.py       # æ–‡æœ¬è§£ç å™¨è®­ç»ƒ
    â”‚   â”œâ”€â”€ eval_text.py        # æ–‡æœ¬è¯„ä¼°
    â”‚   â””â”€â”€ generate_text.py    # æ–‡æœ¬ç”Ÿæˆ
    â””â”€â”€ config/                  # é…ç½®æ–‡ä»¶
        â””â”€â”€ data_config.json    # æ•°æ®é…ç½®
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ (5åˆ†é’Ÿ)

### æ­¥éª¤ 1: é…ç½®ç¯å¢ƒï¼ˆ2 åˆ†é’Ÿï¼‰

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd jiangqf/OmniFlows

# è¿è¡Œä¸€é”®é…ç½®è„šæœ¬
./setup.sh

# æˆ–æ‰‹åŠ¨å®‰è£…
pip install -r requirements.txt && pip install -e .
```

### æ­¥éª¤ 2: å‡†å¤‡æ•°æ®ï¼ˆ1 åˆ†é’Ÿï¼‰

```bash
# å›åˆ°æ ¹ç›®å½•ä¸‹è½½æµ‹è¯•æ•°æ®ï¼ˆstreaming æ¨¡å¼ï¼Œä»… 1000 ä¸ªæ ·æœ¬ï¼‰
cd ../../
python dataset/download_data.py --streaming --max-samples 1000
cd jiangqf/OmniFlows
```

### æ­¥éª¤ 3: å¼€å§‹è®­ç»ƒï¼ˆ2 åˆ†é’Ÿï¼‰

```bash
# è¿è¡Œç¤ºä¾‹è®­ç»ƒè„šæœ¬
./run_example.sh
```

å®Œæˆï¼ğŸ‰

---

## ğŸ”§ ç¯å¢ƒé…ç½®

### è‡ªåŠ¨é…ç½®ï¼ˆæ¨èï¼‰

```bash
./setup.sh
```

è„šæœ¬ä¼šè‡ªåŠ¨å®Œæˆï¼š
- âœ… æ£€æŸ¥ Python ç¯å¢ƒ
- âœ… åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆå¯é€‰ï¼‰
- âœ… å®‰è£…æ‰€æœ‰ä¾èµ–
- âœ… åˆ›å»ºå¿…è¦ç›®å½•
- âœ… å¯é€‰ï¼šä¸‹è½½æ•°æ®å’Œæ¨¡å‹

### æ‰‹åŠ¨é…ç½®

#### 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰

```bash
python3 -m venv omniflow_env
source omniflow_env/bin/activate  # Linux/Mac
```

#### 2. å®‰è£…ä¾èµ–

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

#### 3. å®‰è£… OmniFlow åŒ…

```bash
pip install -e .
```

---

## ğŸ“¦ æ•°æ®é›†ä¸‹è½½

### å¿«é€Ÿæµ‹è¯•ï¼ˆStreaming æ¨¡å¼ï¼Œæ¨èï¼‰

ä¸‹è½½å°‘é‡æ ·æœ¬ç”¨äºå¿«é€Ÿæµ‹è¯•ï¼š

```bash
cd ../../  # å›åˆ° qf/ æ ¹ç›®å½•
python dataset/download_data.py --streaming --max-samples 1000
cd jiangqf/OmniFlows
```

ä¸‹è½½å†…å®¹ï¼š
- WikiText-103: å‰ 1000 ä¸ªæ ·æœ¬
- COCO Caption: å‰ 1000 ä¸ªæ ·æœ¬
- AudioCaps: å‰ 1000 ä¸ªæ ·æœ¬
- LLaVA-CC3M: å‰ 1000 ä¸ªæ ·æœ¬

### ä¸‹è½½å®Œæ•´æ•°æ®é›†

```bash
cd ../../
python dataset/download_data.py  # ä¸‹è½½æ‰€æœ‰æ•°æ®é›†
cd jiangqf/OmniFlows
```

### ä¸‹è½½ç‰¹å®šæ•°æ®é›†

```bash
cd ../../

# åªä¸‹è½½ WikiText
python dataset/download_data.py --wikitext

# ä¸‹è½½å¤šä¸ªæ•°æ®é›†
python dataset/download_data.py --coco --audiocaps

# ä¸‹è½½ 10% å­é›†
python dataset/download_data.py --subset-fraction 0.1

cd jiangqf/OmniFlows
```

### æ•°æ®é›†è¯´æ˜

| æ•°æ®é›† | HuggingFace ID | ç”¨é€” | æ¨¡æ€ |
|--------|---------------|------|------|
| WikiText-103 | `Salesforce/wikitext` | çº¯æ–‡æœ¬è®­ç»ƒ | Text |
| COCO Caption | `lmms-lab/COCO-Caption` | å›¾åƒæè¿° | Image + Text |
| AudioCaps | `OpenSound/AudioCaps` | éŸ³é¢‘æè¿° | Audio + Text |
| LLaVA-CC3M | `liuhaotian/LLaVA-CC3M-Pretrain-595K` | è§†è§‰å¯¹è¯ | Image + Text |

æ•°æ®ä¿å­˜ä½ç½®ï¼š`../../dataset/data/`

---

## ğŸ¤– æ¨¡å‹ä¸‹è½½

### ä½¿ç”¨ä¸‹è½½è„šæœ¬

```bash
# ä¸‹è½½æ‰€æœ‰å¿…éœ€æ¨¡å‹
python download_models.py

# åªä¸‹è½½ç‰¹å®šæ¨¡å‹
python download_models.py --models clip_vit_l t5_large

# å¼ºåˆ¶é‡æ–°ä¸‹è½½
python download_models.py --force
```

### éœ€è¦çš„æ¨¡å‹

æ¨¡å‹è‡ªåŠ¨ä¸‹è½½åˆ° `models/` ç›®å½•ï¼š

1. **CLIP-ViT-L-14** (~1.7 GB)
   - HF ID: `laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K`
   - ç”¨é€”ï¼šå›¾åƒå’Œæ–‡æœ¬ç¼–ç å™¨

2. **T5-Large** (~2.8 GB)
   - HF ID: `google/flan-t5-large`
   - ç”¨é€”ï¼šæ–‡æœ¬ç¼–ç å™¨

3. **LanguageBind Audio** (~1.4 GB)
   - HF ID: `LanguageBind/LanguageBind_Audio_FT`
   - ç”¨é€”ï¼šéŸ³é¢‘ç¼–ç å™¨

4. **OmniFlow ä¸»æ¨¡å‹** (éœ€è¦æ‰‹åŠ¨é…ç½®)
   - åŒ…å«ï¼šTransformer + VAE + Text VAE
   - ä½ç½®ï¼š`models/OmniFlow-v0.5/`

---

## ğŸ¯ è®­ç»ƒæ¨¡å‹

### ä½¿ç”¨ç¤ºä¾‹è„šæœ¬ï¼ˆæœ€ç®€å•ï¼‰

```bash
./run_example.sh
```

é»˜è®¤é…ç½®ï¼š
- MLP Text Decoder Head
- 1 epoch
- Batch size: 4
- Learning rate: 1e-4
- è¾“å‡ºï¼š`checkpoints/text_decoder_head_test/mlp_head/`

### è‡ªå®šä¹‰è®­ç»ƒå‚æ•°

```bash
python scripts/train_text.py \
    --model_path models/OmniFlow-v0.5 \
    --data_config config/data_config.json \
    --use_text_decoder_head \
    --text_decoder_head_dim 2048 \
    --batch_size 8 \
    --num_epochs 5 \
    --lr 2e-4 \
    --output_dir checkpoints/my_training \
    --log_interval 100 \
    --eval_interval 500 \
    --save_interval 2000
```

### é‡è¦å‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--model_path` | é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ | å¿…éœ€ |
| `--data_config` | æ•°æ®é…ç½®æ–‡ä»¶ | å¿…éœ€ |
| `--use_text_decoder_head` | ä½¿ç”¨æ–‡æœ¬è§£ç å¤´ | False |
| `--use_vq_codebook` | ä½¿ç”¨ VQ codebook | False |
| `--text_decoder_head_dim` | è§£ç å¤´è¾“å‡ºç»´åº¦ | 2048 |
| `--use_latent_refiner` | ä½¿ç”¨ LatentRefiner | False |
| `--batch_size` | æ‰¹å¤§å° | 16 |
| `--num_epochs` | è®­ç»ƒè½®æ•° | 3 |
| `--lr` | å­¦ä¹ ç‡ | 1e-4 |

---

## ğŸ§ª å®éªŒé…ç½®

### Baselineï¼šç®€å• MLP Head

æœ€åŸºç¡€é…ç½®ï¼Œæ—  VQï¼Œæ—  Refinerã€‚

```bash
python scripts/train_text.py \
  --model_path ./models/OmniFlow-v0.5 \
  --data_config ./config/data_config.json \
  --use_text_decoder_head \
  --text_decoder_head_dim 64 \
  --batch_size 8 \
  --num_epochs 1 \
  --output_dir ./checkpoints/baseline_head
```

**ç‰¹ç‚¹**:
- è¾“å‡ºç»´åº¦ï¼š64-d latent
- å‚æ•°é‡ï¼šæœ€å°‘
- è®­ç»ƒé€Ÿåº¦ï¼šæœ€å¿«

### å®éªŒ Aï¼šMLP Head + LatentRefiner

åœ¨ baseline åŸºç¡€ä¸Šæ·»åŠ  LatentRefiner MLP ä¼˜åŒ–è¡¨å¾ã€‚

```bash
python scripts/train_text.py \
  --model_path ./models/OmniFlow-v0.5 \
  --data_config ./config/data_config.json \
  --use_text_decoder_head \
  --text_decoder_head_dim 64 \
  --use_latent_refiner \
  --latent_refiner_hidden_dim 256 \
  --latent_refiner_layers 2 \
  --batch_size 8 \
  --num_epochs 1 \
  --output_dir ./checkpoints/head_plus_refiner
```

**ç‰¹ç‚¹**:
- è¾“å‡ºç»´åº¦ï¼š64-d latent
- é¢å¤–å‚æ•°ï¼š~50K (LatentRefiner)
- LatentRefiner ç»“æ„ï¼šInput â†’ MLP(256) â†’ MLP(256) â†’ Output + Residual

### å®éªŒ Bï¼šVQ Codebook Head

ä½¿ç”¨ VQ (Vector Quantization) codebook å‡å°‘è¿ç»­-ç¦»æ•£æ˜ å°„è¯¯å·®ã€‚

```bash
python scripts/train_text.py \
  --model_path ./models/OmniFlow-v0.5 \
  --data_config ./config/data_config.json \
  --use_text_decoder_head \
  --use_vq_codebook \
  --text_decoder_head_dim 64 \
  --batch_size 8 \
  --num_epochs 1 \
  --output_dir ./checkpoints/vq_head
```

**ç‰¹ç‚¹**:
- è¾“å‡ºç»´åº¦ï¼š64-d latent
- VQ Codebook å¤§å°ï¼š8192
- é¢å¤–æŸå¤±ï¼šVQ loss

### å®éªŒ A+Bï¼šVQ Head + LatentRefiner

å®Œæ•´é…ç½®ï¼Œç»“åˆ VQ å’Œ Refinerã€‚

```bash
python scripts/train_text.py \
  --model_path ./models/OmniFlow-v0.5 \
  --data_config ./config/data_config.json \
  --use_text_decoder_head \
  --use_vq_codebook \
  --text_decoder_head_dim 64 \
  --use_latent_refiner \
  --latent_refiner_hidden_dim 256 \
  --latent_refiner_layers 2 \
  --batch_size 8 \
  --num_epochs 1 \
  --output_dir ./checkpoints/vq_head_plus_refiner
```

**ç‰¹ç‚¹**:
- VQ quantization + Latent refinement
- å‚æ•°é‡ï¼šæœ€å¤š
- ç†è®ºä¸Šè¡¨ç°æœ€å¥½

---

## ğŸ“Š è¯„ä¼°æ¨¡å‹

### 1. ç”Ÿæˆé¢„æµ‹ç»“æœ

```bash
python scripts/generate_text.py \
    --model_path models/OmniFlow-v0.5 \
    --checkpoint checkpoints/baseline_head/best_*.pt \
    --data_config config/data_config.json \
    --output predictions.json \
    --batch_size 4
```

### 2. è®¡ç®—è¯„ä¼°æŒ‡æ ‡

```bash
python scripts/eval_text.py \
    --predictions predictions.json \
    --metrics bleu rouge meteor \
    --output_json eval_results.json
```

æ”¯æŒæŒ‡æ ‡ï¼š
- **BLEU-4**: æ–‡æœ¬ç”Ÿæˆè´¨é‡
- **ROUGE-L**: æ–‡æœ¬ç›¸ä¼¼åº¦
- **METEOR**: ç»¼åˆè¯„ä¼°

### 3. å¯¹æ¯”å®éªŒ

è¯„ä¼°æ‰€æœ‰å®éªŒé…ç½®å¹¶å¯¹æ¯”ï¼š

```bash
# Baseline
python scripts/generate_text.py \
  --checkpoint ./checkpoints/baseline_head/best_*.pt \
  --output ./results/baseline_predictions.json

# MLP + Refiner
python scripts/generate_text.py \
  --checkpoint ./checkpoints/head_plus_refiner/best_*.pt \
  --output ./results/refiner_predictions.json

# VQ Head
python scripts/generate_text.py \
  --checkpoint ./checkpoints/vq_head/best_*.pt \
  --output ./results/vq_predictions.json

# è¯„ä¼°æ‰€æœ‰ç»“æœ
python scripts/eval_text.py --predictions ./results/baseline_predictions.json
python scripts/eval_text.py --predictions ./results/refiner_predictions.json
python scripts/eval_text.py --predictions ./results/vq_predictions.json
```

---

## ğŸ› å¸¸è§é—®é¢˜

### 1. CUDA å†…å­˜ä¸è¶³

**é”™è¯¯**: `CUDA out of memory`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# å‡å° batch size
python scripts/train_text.py --batch_size 2

# å‡å°åºåˆ—é•¿åº¦
python scripts/train_text.py --max_length 128
```

### 2. æ•°æ®é›†ä¸‹è½½å¤±è´¥

**é”™è¯¯**: `Connection timeout` æˆ– `403 Forbidden`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# ä½¿ç”¨ HuggingFace é•œåƒï¼ˆä¸­å›½ç”¨æˆ·ï¼‰
export HF_ENDPOINT=https://hf-mirror.com

# é‡æ–°ä¸‹è½½
cd ../../
python dataset/download_data.py --streaming --max-samples 1000
```

### 3. æ¨¡å‹åŠ è½½é”™è¯¯

**é”™è¯¯**: `Model path not found`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥æ¨¡å‹è·¯å¾„
ls -la models/OmniFlow-v0.5/

# ç¡®ä¿ç›®å½•ç»“æ„æ­£ç¡®
models/OmniFlow-v0.5/
â”œâ”€â”€ transformer/
â”œâ”€â”€ vae/
â”œâ”€â”€ text_vae/
â”œâ”€â”€ text_encoder_2/
â””â”€â”€ vae_tokenizer/
```

### 4. éŸ³é¢‘å¤„ç†é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:
éŸ³é¢‘ VAE ä¼šè‡ªåŠ¨ä¸‹è½½ã€‚å¦‚é‡é—®é¢˜ï¼š
```bash
pip install librosa torchaudio soundfile
```

---

## ğŸ“ˆ æ€§èƒ½å‚è€ƒ

### ä¸åŒ GPU çš„è®­ç»ƒé€Ÿåº¦

| GPU | Batch Size | è®­ç»ƒé€Ÿåº¦ | å†…å­˜ä½¿ç”¨ |
|-----|-----------|---------|---------|
| RTX 3090 (24GB) | 8 | ~200 steps/min | ~18 GB |
| RTX 4090 (24GB) | 16 | ~350 steps/min | ~22 GB |
| A100 (40GB) | 32 | ~600 steps/min | ~35 GB |
| V100 (16GB) | 4 | ~150 steps/min | ~14 GB |

### å®éªŒç»“æœå¯¹æ¯”ï¼ˆé¢„æœŸï¼‰

| é…ç½® | å‚æ•°é‡ | è®­ç»ƒæ—¶é—´ | BLEU | ROUGE-L | METEOR |
|------|--------|---------|------|---------|--------|
| Baseline | ä½ | 1x | åŸºå‡† | åŸºå‡† | åŸºå‡† |
| +Refiner | ä¸­ | 1.1x | â†‘ | â†‘ | â†‘ |
| VQ Head | ä¸­ | 1.2x | â†‘ | â†‘ | â†‘ |
| VQ+Refiner | é«˜ | 1.3x | â†‘â†‘ | â†‘â†‘ | â†‘â†‘ |

---

## ğŸ’¡ æç¤º

1. **å¿«é€ŸéªŒè¯**: å…ˆç”¨ streaming æ¨¡å¼ä¸‹è½½å°‘é‡æ•°æ®æµ‹è¯•æµç¨‹
2. **ç›‘æ§è®­ç»ƒ**: å…³æ³¨ PPL å’Œ Accuracy çš„æ”¶æ•›æƒ…å†µ
3. **GPU å†…å­˜**: ä¸è¶³æ—¶å‡å° `batch_size` æˆ– `max_length`
4. **å…¬å¹³å¯¹æ¯”**: ç¡®ä¿æ‰€æœ‰å®éªŒä½¿ç”¨ç›¸åŒæ•°æ®é›†å’Œè¯„ä¼°é›†

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [è®­ç»ƒè„šæœ¬](scripts/train_text.py) - å®Œæ•´è®­ç»ƒä»£ç 
- [æ¨¡å‹å®šä¹‰](omniflow/models/text_decoder_head.py) - TextDecoderHead å’Œ LatentRefiner
- [æ•°æ®é…ç½®](config/data_config.json) - æ•°æ®é›†é…ç½®

---

**ç¥è®­ç»ƒé¡ºåˆ©ï¼** ğŸ‰
